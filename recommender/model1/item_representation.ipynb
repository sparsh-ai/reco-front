{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install img2vec_pytorch\n",
    "# conda install faiss-cpu -c pytorch -n torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from img2vec_pytorch import Img2Vec\n",
    "from PIL import Image\n",
    "import faiss\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '../../data'\n",
    "artifact_path = 'artifacts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = []\n",
    "for path in Path(image_path).rglob('*.jpg'):\n",
    "    img_paths.append(path)\n",
    "# img_paths[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sparsh.agarwal\\.conda\\envs\\torch\\lib\\site-packages\\torchvision\\transforms\\transforms.py:279: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 512)\n"
     ]
    }
   ],
   "source": [
    "img2vec = Img2Vec(cuda=False)\n",
    "vectors = img2vec.get_vec([Image.open(ipath) for ipath in img_paths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_vectors = {ipath.stem:vectors[iindex] for iindex, ipath in enumerate(img_paths)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_paths = {ipath.stem:ipath for ipath in img_paths}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(item_vectors, open(os.path.join(artifact_path,\"item_vectors.p\"), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "index = faiss.IndexFlatL2(d)\n",
    "index.add(np.array(list(item_vectors.values())))\n",
    "print(index.ntotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 2 4 1]\n",
      " [1 2 0 4]\n",
      " [2 1 0 4]\n",
      " [3 4 5 6]\n",
      " [4 3 2 5]]\n",
      "[[  0.      327.47327 401.84265 411.65393]\n",
      " [  0.      206.0236  411.65393 428.9434 ]\n",
      " [  0.      206.0236  327.47327 352.76587]\n",
      " [  0.      273.33212 343.14578 362.2754 ]\n",
      " [  0.      273.33212 352.76587 392.9403 ]]\n"
     ]
    }
   ],
   "source": [
    "# print(index.is_trained)\n",
    "k = 4 # we want to see 4 nearest neighbors\n",
    "D, I = index.search(vectors[:5], k) # sanity check\n",
    "print(I)\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/facebookresearch/faiss/wiki/Getting-started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topk_similar(itemid, topk=2):\n",
    "    _, I = index.search(item_vectors[str(itemid)].reshape(1,-1), topk+1)\n",
    "    return [list(item_vectors.keys())[i] for i in I.flatten()][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10008', '10005']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_similar('10006')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topk_distance(itemid, topk=2):\n",
    "    D, I = index.search(item_vectors[str(itemid)].reshape(1,-1), topk+1)\n",
    "    return {list(item_vectors.keys())[i]:j for (i,j) in zip(I.flatten(),D.flatten())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'10006': 0.0, '10008': 247.23978, '10005': 247.81348}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_distance('10006')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D, I = index.search(item_vectors[str('10001')].reshape(1,-1), 2+1)\n",
    "# [list(item_vectors.keys())[i] for i in I.flatten()][1:]\n",
    "# {i:j for (i,j) in zip(I.flatten(),D.flatten())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sparsh.agarwal\\.conda\\envs\\torch\\lib\\site-packages\\torchvision\\transforms\\transforms.py:279: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\n"
     ]
    }
   ],
   "source": [
    "!python itemrep_training.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Hello, world\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "# log = logging.getLogger(\"my\")\n",
    "# log.setLevel(logging.INFO)\n",
    "logging.info(\"Hello, world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading item vectors\n",
      "INFO:root:Loading indexer\n"
     ]
    }
   ],
   "source": [
    "from itemrep_inference import topk_similar as topsim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
